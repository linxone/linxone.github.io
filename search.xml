<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>自定义OVS再编译</title>
      <link href="2021/10/11/%E8%87%AA%E5%AE%9A%E4%B9%89OVS%E5%86%8D%E7%BC%96%E8%AF%91/"/>
      <url>2021/10/11/%E8%87%AA%E5%AE%9A%E4%B9%89OVS%E5%86%8D%E7%BC%96%E8%AF%91/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>KVM_QEMU-Setup</title>
      <link href="2021/10/11/KVM-Setup/"/>
      <url>2021/10/11/KVM-Setup/</url>
      
        <content type="html"><![CDATA[<h2 id="一、-KVM-虚拟机安装"><a href="#一、-KVM-虚拟机安装" class="headerlink" title="一、 KVM 虚拟机安装"></a>一、 KVM 虚拟机安装</h2><h3 id="1-1-前提条件"><a href="#1-1-前提条件" class="headerlink" title="1.1 前提条件"></a>1.1 前提条件</h3><p>在安装之前，确保主机支持 KVM 虚拟化，并且系统必须拥有支持VT-x(vmx) 的 Intel 处理器或者支持 AMD-V(svm) 技术的 AMD 处理器。输入下面的grep命令来看看你的吹气是否支持硬件虚拟化：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -Eoc &#x27;(vmx|svm)&#x27; /proc/cpuinfo</span><br></pre></td></tr></table></figure><p>如果 CPU 支持硬件虚拟化，这个命令将会打印出大于0的数字，这代表 CPU 核心数目。否则，如果输出为0，它意味着这个 CPU 不支持硬件虚拟化。</p><h3 id="1-2-安装-KVM"><a href="#1-2-安装-KVM" class="headerlink" title="1.2 安装 KVM"></a>1.2 安装 KVM</h3><p>运行下面的命令安装 KVM，和额外的虚拟化管理软件包：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install qemu-kvm libvirt-bin bridge-utils virtinst virt-manager</span><br></pre></td></tr></table></figure><ul><li>qemu-kvm - 为 KVM 管理程序提供硬件模拟的软件程序</li><li>libvirt-bin - 管理虚拟化平台的软件</li><li>bridge-utils - 用来配置网络桥接的命令行工具</li><li>virtinst - 用来创建虚拟机的命令行工具</li><li>virt-manager - 提供一个易用的图形界面，并且通过libvirt 支持用于管理虚拟机的命令行工具</li></ul><p>一旦软件包被安装好，libvirt 守护程序将会自动启动。你可以通过运行下面的命令，验证它：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl is-active libvirtd</span><br></pre></td></tr></table></figure><p>输出：active</p><p>接下来就可以根据个人的需求，使用 virt-manager 图形界面安装虚拟机即可。</p><h2 id="二、-拓扑搭建"><a href="#二、-拓扑搭建" class="headerlink" title="二、 拓扑搭建"></a>二、 拓扑搭建</h2><p>首先，这里厘清一个基本概念问题。<br>OvS添加的虚拟 bridge 和 port 是什么？</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo ovs-vsctl add-br br0     // 创建一个叫br0的网桥</span><br><span class="line">sudo ovs-vsctl add-port br0 vp  -- set Interface vp type=internal  // 创建一个 internal类型的虚拟端口 vp，默认类型即是 internal</span><br></pre></td></tr></table></figure><ul><li>br0：<ul><li>对于OvS和宿主主机所创建的VMs看来是创建了一个虚拟的交换机：(VM在网络配置NIC中选择 br0，相当于将 VM 和 br0 连接起来，这样相当于 VM 使用默认类型internal端口)</li><li>而对于OvS宿主主机而言，br0是一个虚拟网卡；(需要注意的是，若用ifconfig可以看到一个叫 virbr0 虚拟网卡，这个virbr0并不是OvS创建的br0，而是安装KVM默认自带的虚拟网卡。OvS创建的br0默认是不显示，若配上ip地址，便可以用ifconfig命令看到br0)</li></ul></li><li>vp：对于OvS看来就是交换机br0上的的一个端口/接口，而对于OvS宿主主机和宿主主机所创建的vm而言，vp都是一个虚拟网卡；</li></ul><p>这里举例一个拓扑图配置方案，OvS配置命令如下，以HOST1为例(HOST2类似操作):</p><img src="/2021/10/11/KVM-Setup/single-Eth.png" alt="single-Eth" style="zoom:33%;"><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo ovs-vsctl add-br br0     // 创建一个叫br0的网桥</span><br><span class="line">sudo ovs-vsctl add-port br0 phy-eth    // 将宿主主机物理网卡 phy-eth 绑定到网桥 br0 上，并且要与物理网卡同名，注意的是OvS不能绑定宿主主机虚拟网</span><br></pre></td></tr></table></figure><p>接下来，给已经创建KVM虚拟机配置IP，并确定所有虚拟机VMs网卡配置NIC都以 Bridge 方式绑定到 br0。这里是将 VM1 VM2 VM3 VM4划分在同一个子网内。IPv4地址分别是 10.0.0.11 10.0.0.12 10.0.0.13 10.0.0.14，Netmask都是 255.255.255.0 。<br>HOST2同上类似操作；</p><img src="/2021/10/11/KVM-Setup/multi-Eths.png" alt="multi-Eths" style="zoom:33%;"><p>这里也可以为每个 VM 在 OvS 上配置一个单独端口</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo ovs-vsctl add-port br0 virt-port1 -- set Interface virt-port1 type=internal// HOST1上创建一个叫 virt-port1 的虚拟端口</span><br><span class="line">sudo ovs-vsctl add-port br0 virt-port2 -- set Interface virt-port2 type=internal// HOST1上创建一个叫 virt-port2 的虚拟端口</span><br><span class="line">sudo ovs-vsctl add-port br0 virt-port3 -- set Interface virt-port3 type=internal// HOST2上创建一个叫 virt-port3 的虚拟端口</span><br><span class="line">sudo ovs-vsctl add-port br0 virt-port4 -- set Interface virt-port4 type=internal// HOST2上创建一个叫 virt-port4 的虚拟端口</span><br></pre></td></tr></table></figure><p>接下来，同样给是已经创建KVM虚拟机配置IP，不同的是，VMs网卡配置NIC都以 Bridge 方式绑定到对应的 virt-port[1-4]</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>DPDK 17.08.1-Setup</title>
      <link href="2021/08/09/DPDK-Setup/"/>
      <url>2021/08/09/DPDK-Setup/</url>
      
        <content type="html"><![CDATA[<h3 id="DPDK-准备"><a href="#DPDK-准备" class="headerlink" title="DPDK 准备"></a>DPDK 准备</h3><ol><li><p>环境</p><p>Kernel version &gt;= 2.6.34, glibc &gt;= 2.7, DUN make 等</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install build-essential</span><br></pre></td></tr></table></figure><p>若是多核环境需要安装        </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install numactl</span><br><span class="line">sudo apt-get install libnuma-dev</span><br></pre></td></tr></table></figure></li><li><p>版本选择</p><ul><li>Ubuntu 16.04</li><li><a href="https://core.dpdk.org/download/">DPDK 17.08</a></li></ul></li></ol><h3 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h3><ol><li>下载 DPDK 源码，进入 dpdk/usertools 目录</li><li>执行 ./dpdk-set.sh，执行安装脚本<ul><li>根据配置，选择对应安装版本 x86_64-native-linxapp-gcc</li><li>插入用户态驱动，Insert IGB UIO module</li><li>设置巨页</li><li>绑定网卡</li></ul></li></ol><h3 id="DPDK-SWITCH安装"><a href="#DPDK-SWITCH安装" class="headerlink" title="DPDK-SWITCH安装"></a>DPDK-SWITCH安装</h3><ol><li><p><a href="https://github.com/dfshan/dpdk-switch.git">源码链接</a></p></li><li><p>环境要求</p><ul><li><p>环境变量设置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export RTE_SDK=&quot;/path/dpdk&quot;  // 这里填的是dpdk源码的本地路径</span><br><span class="line"></span><br><span class="line">export RTE_TARGET=&quot;x86_64-native-linuxapp-gcc  // 选择安装版本</span><br></pre></td></tr></table></figure></li><li><p>DPDK 与 DPDK-SWITCH 版本需要一致，17.08.1</p></li><li><p>libConfuse &gt;= 2.7 </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install libconfuse-dev</span><br></pre></td></tr></table></figure></li></ul></li><li><p> 安装步骤参考 README 即可</p></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Metronome:adaptive and precise intermittent packet retrieval in DPDK</title>
      <link href="2021/04/25/Metronome/"/>
      <url>2021/04/25/Metronome/</url>
      
        <content type="html"><![CDATA[<p>这篇 paper 收录于 <a href="https://conferences2.sigcomm.org/co-next/2020/#!/program">CoNext2020</a></p><hr><h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>Issue: DPDK works at the cost of precious CPU resources, dedicated to continuously poll the NICs.<br>Innovations: </p><ul><li>a microseconds time-scale sleep function, named hr_slepp();</li><li>an efficient multi-thead operation</li></ul><hr><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><ol><li>先介绍 DPDK 有着非常出色的包处理性能，它需要有些 CPU-cores 轮询 NICs 是否有要进来的包。这样带来就是 不论有多少包来，CPU-cores 利用率都是 100%，同时带来大量电力消耗；</li><li>DCN中对于某一条链路来看，其大部分时间是空闲的，而 DPDK polling 会浪费 CPU 资源，所以用一种间歇性的、sleep&amp;wake 代替 polling 是更好的；<ol><li>虽然 DCN 是设计用来处理峰值负载（就是让它来处理比较重的任务），通过微软和脸书相关数据显示 DCN 性能并没有得到充分的利用；（微软：他们有46-99%的机架对根本没有交换流量；脸书：最繁忙的5%链路利用率从23%到46%不等，核心网络链路（迄今为止压力最大的链路）的利用率从未超过25%）</li><li>CPU 性能一直在提高，但似乎也快到达一个停滞点，并且现在 CPU 负担也越来越重；</li><li>在多租户云服务中，用户租用的是虚拟 CPU，它以时间共享的方式映射到物理 CPU/分时。而 DPDK 应用是独占 CPU-cores，这样会使不同用户之间资源共享变得复杂设置不可行；</li></ol></li><li>本文提出了 Metronome，这是一种用睡眠和唤醒的间歇性功能来取代连续的 DPDK 轮询的方法。<ol><li>该思路是显而易见的，但是在具体实践中由于缺乏精确的微秒级睡眠函数，进展受阻 —&gt; hr_sleep()</li><li>a novel architecture and operating mode for DPDK，队列空闲的时候会动态将 poll 改成 sleep&amp;wake，可以根据负载调整睡眠时间；</li></ol></li></ol><hr><h3 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a><strong>Related Work</strong></h3><p>处理从网卡传入的数据流时，有两种方法：polling、interrupt；</p><ol><li><p>Polling：Intel 在低流量情况下，通过逐步降低 CPU 时钟频率，以此降低能源消耗；<br>1.1 虽然降低 CPU 时钟频率可以降低能源消耗，但是 CPU-cores 依旧是被 DPDK app 独占，不能用于其他任务；</p><p>1.2 在云环境下，降低 CPU 时钟频率是不可取的</p><ul><li>CPUs 是在不同的进程和用户之间共享</li><li>Provides 是希望 CPUs 性能可以得到充分利用</li></ul><p>Paper 通过优化 OS 服务，细粒度控制 DPDK 线程使用 CPU 的时间线，并将其称之为“METRONOME/节拍器”；</p></li><li><p>Interrupt：网卡的巨大改进（从1GbE到100GbE），以及由于摩尔定律的结束和Dennard Scaling而导致的CPU性能的滞后，证明了基于中断的方法的性能有所限制；</p></li></ol><hr><h3 id="METRONOME-ARCHITECTURE"><a href="#METRONOME-ARCHITECTURE" class="headerlink" title="METRONOME ARCHITECTURE"></a><strong>METRONOME ARCHITECTURE</strong></h3><ol><li><p>Fine-Grain Thread Sleep Service</p><ol><li><p>目标：如果没有数据包处理时，线程不能占用 CPU；需要时，线程可以继续使用 CPU；</p></li><li><p>介绍当前 Linux 内核传统实现对线程睡眠是基于 nanosleep() 系统调用 =&gt;在 kernel mode 时，主要利用调度子系统（管理线程的运行队列），和高分辨率的定时器子系统（可以向内核的定时器发布过期请求）；</p><ul><li>定时器子系统：数据结构，用于保存有序的定时器过期请求集；一个定时器过期与x86处理器板上的高精度事件定时器（HPET）的中断相关联</li></ul></li><li><p>nanosleep() ‘s limitations：nanosleep() 系统调用前言部分是需要传入 struct timespec 的数据结构（表）来指定睡眠阶段的持续时间，而该结构保存在用户空间，这就涉及到 a user-to-kernel data move operation</p><ul><li>引入 user-to-kernel 操作，在真正进入睡眠之前增加了指令</li><li>执行 the preamble 部分是会被其他线程抢占，可能会导致睡眠期拉长，相应地也多了一些必要开销</li><li>若使用优先级线程方法解决，会降低配置CPU调度策略的自由度</li></ul></li><li><p>hr_sleep() to the rescue：大概意思就是基于nanosleep()，重新设计了一个传入的时间参数存放在 CPU 寄存器避免了上述麻烦，而且它时间精度更好</p></li></ol></li><li><p>Actual Thread Operations ：Rx queues can be efficiently shared among multiple threads</p><ul><li>motivation：目前dpdk是one rx queue不允许多线程共享的，也就说特定的一个或者是一组rx queue对应只有一个thread负责（这也是因为poll mode 线程不断轮询）。所以想实现rx queue 和dpdk thraed解藕。一个/一组 rx queue(s) 可以被多个/不同thread管理【不是多线程同时管理queue】</li><li>try_lock()：不依靠任何额外的操作系统服务来实现竞赛；相反，我们纯粹在用户空间通过原子读-修改-写指令来实现竞赛解决协议，特别是X86处理器上的CMPXCHG指令，它已经被用来建立一个轻量级的trylock()服务</li><li>过程：对于每个队列，每个线程都试图获得相关的锁，如果获得锁失败，则转到下一个队列。如果获锁成功，也就是线程赢得了锁的竞赛，只要该 queue 还有传入的数据包，它就会一直处理该队列，一旦队列空闲，它就会释放锁，该线程进入 sleep。  —&gt; 关键就是 How a thread can elicit an awake-timeout period without incurring an Rx queue filling ？</li></ul></li></ol><hr><h3 id="METRONOME-ADAPTIVE-TUNING"><a href="#METRONOME-ADAPTIVE-TUNING" class="headerlink" title="METRONOME ADAPTIVE TUNING"></a><strong>METRONOME ADAPTIVE TUNING</strong></h3><ol><li><p>Metronome Multi-Threading Strategy ：how to configure the awake timeouts of the different deployed Metronome threads?</p><ul><li>方法是：a diversity-based strategy for configuring the wake-up timeouts of different threads, which aims at mimicking a classical <strong>primary/backup</strong> approach（primary thread睡眠超时时间短𝑇𝑆 ，backup thread睡眠超时时间长𝑇𝐿）</li><li>规则<ul><li>primary thread：当一个线程 trylock() 成功取得 rx queue 管理权开始对 queue 进行“卸货”， timeout -&gt; 𝑇𝑆</li><li>backup thread：当一个线程 trylock() 失败，也就是说当前有另个线程已经在“卸货”了，timeout -&gt; 𝑇𝐿</li></ul></li></ul><p>在高负载情况下，在当primary线程可能受到OS调度影响不能够及时wakeup时候，backup线程可以进行一个补充；在低负载情况下，因为所有线程可能同时处于 primary state，所以可以放松对 Ts 限制；</p></li><li><p>Metronome Analysis + Metronome Adaptation and Tradeoffs</p><p>通过分析两种情况：highload 和 lowload</p><ul><li>at high load：在同一时间内只有一个线程（有可能一直是同一个也可能是不同）处于 primary；</li><li>at low load：比较特别情况就是每个线程都有可能是 primary；</li></ul></li></ol><hr><h3 id="个人解析思路"><a href="#个人解析思路" class="headerlink" title="个人解析思路"></a>个人解析思路</h3><p>Metronome: adaptive and precise intermittent packet retrieval in DPDK</p><ul><li>adaptive：sleep timeout 时间可以调节</li><li>precise：hr_sleep() 时间精度比 nanosleep() 更细</li><li>intermittent：将 DPDK poll mode 改成 sleep/wake_up mode</li></ul><p>Motivation</p><p>​    DPDK 的 poll mode 不断询问 NICs 是否有新的数据包来，所以不论数据包是来多来少，对 CPU 的占用总是100%。并且在实际中 DCN 大多数链路的大部分时间是处于低载状态甚至是空载。</p><p>​    显而易见，这样会造成很多不必要能源消耗，以及对 CPU 的独占。</p><p>Metronome</p><ol><li><p>poll mode –&gt; timer (sleep&amp;wake_up)</p><ul><li>hr_sleep() 实现较精确的微秒级睡眠函数</li><li>primary 睡 Ts, backup 睡 Tl</li><li>Ts 是 adative</li></ul></li><li><p>Multiple threads operation</p><ul><li><p>a classical <strong>primary/backup</strong> approach</p></li><li><p>trylock() 解决协调/加锁问题</p></li></ul></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>OVS 源码安装</title>
      <link href="2021/04/21/OVS-Setup/"/>
      <url>2021/04/21/OVS-Setup/</url>
      
        <content type="html"><![CDATA[<h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><p>OVS官方文档 <a href="https://docs.openvswitch.org/en/latest/intro/install/general/#general-build-reqs">Ovs Document</a></p><p>这里笔者使用系统环境时 Ubuntu 18.04，Kernel version &gt;= 5.4.0</p><h2 id="一、-OVS安装"><a href="#一、-OVS安装" class="headerlink" title="一、 OVS安装"></a>一、 OVS安装</h2><h3 id="Depencies"><a href="#Depencies" class="headerlink" title="Depencies"></a>Depencies</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install build-essential make</span><br><span class="line">sudo apt install autoconf automake libtool</span><br></pre></td></tr></table></figure><h3 id="1-1-Obtaining-Open-vSwitch-Sources"><a href="#1-1-Obtaining-Open-vSwitch-Sources" class="headerlink" title="1.1 Obtaining Open vSwitch Sources"></a>1.1 Obtaining Open vSwitch Sources</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/openvswitch/ovs.git</span><br></pre></td></tr></table></figure><h3 id="1-2-Bootstrapping-非-git-获取下来源码，略过"><a href="#1-2-Bootstrapping-非-git-获取下来源码，略过" class="headerlink" title="1.2 Bootstrapping (非 git 获取下来源码，略过)"></a>1.2 Bootstrapping (非 git 获取下来源码，略过)</h3><p>在ovs根目录下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./boot.sh</span><br></pre></td></tr></table></figure><h3 id="1-3-Configuring"><a href="#1-3-Configuring" class="headerlink" title="1.3 Configuring"></a>1.3 Configuring</h3><p>在ovs根目录下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./configure</span><br></pre></td></tr></table></figure><h3 id="1-4-Building"><a href="#1-4-Building" class="headerlink" title="1.4 Building"></a>1.4 Building</h3><p>在ovs根目录下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">make -j 8// -j 8 选项并行编译加速</span><br><span class="line">make install</span><br></pre></td></tr></table></figure><h3 id="1-5-ovs工具脚本导入"><a href="#1-5-ovs工具脚本导入" class="headerlink" title="1.5 ovs工具脚本导入"></a>1.5 ovs工具脚本导入</h3><p>ovs提供一套实用工具ovs-ctl utility，供用户使用，其默认存放路径在‘/usr/local/share/openvswitch/scripts’;</p><p>这里推荐直接将路径添加到sudoers  <code>sudo visudo</code> (或者也可以使用 ovs 时切换成 root 用户)：        </p><p>在  <code>Defaults    secure_path=</code> 末尾添加  <code>:/usr/local/share/openvswitch/scripts</code></p><h3 id="1-6-ovs启动"><a href="#1-6-ovs启动" class="headerlink" title="1.6 ovs启动"></a>1.6 ovs启动</h3><p>ovs-ctl提供启动和停止 ovsdb-server 和 ovs-vswitchd ；若需要个性化启动方式，见参考文档。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ovs-ctl start</span><br></pre></td></tr></table></figure><p>可使用<code>ps -e | grep ovs</code>查看验证ovs是否启动成功；若ovs成功运行，可以看到 ovs-vswitchd 和 ovsdb-server。<br>注意！ovs-vswitchd是ovs很重要模块，若未启动，后续增删网桥或者端口会出现问题。</p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
